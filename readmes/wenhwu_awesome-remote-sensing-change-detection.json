{
  "repo_name": "wenhwu_awesome-remote-sensing-change-detection",
  "readme_content": "# <p align=center>`Awesome Remote Sensing Change Detection`</p>\n[![Awesome](https://cdn.rawgit.com/sindresorhus/awesome/d7305f38d29fed78fa85652e3a63e154dd8e8829/media/badge.svg)](https://github.com/sindresorhus/awesome) [![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://GitHub.com/Naereen/StrapDown.js/graphs/commit-activity) [![PR's Welcome](https://img.shields.io/badge/PRs-welcome-brightgreen.svg?style=flat)](http://makeapullrequest.com) [![made-with-Markdown](https://img.shields.io/badge/Made%20with-Markdown-1f425f.svg)](http://commonmark.org)\n\nList of datasets, codes, and contests related to remote sensing change detection.\n\n# Contents\n\n- [Dateset](#dateset)\n  - [Multispectral](#multispectral)\n    - [With Label](#with-label)\n    - [Without Label](#without-label)\n  - [Hyperspectral](#hyperspectral)\n  - [3D](#3d)\n- [Code](#code)\n  - [Multispectral](#multispectral-1)\n    - [Traditional Method](#traditional-method)\n    - [Deep Learning](#deep-learning)\n      - [2D](#2d)\n      - [3D](#3d-1)\n  - [SAR](#sar)\n  - [Hyperspectral](#hyperspectral-1)\n- [Contest](#contest)\n- [Reference](#reference)\n\n# Dateset\n\n## Multispectral\n\n### With Label   \n\n- 2023.[SMARS (Simulated Multimodal Aerial Remote Sensing) dataset](https://www.sciencedirect.com/science/article/pii/S092427162300254X?dgcid=rss_sd_all)      \nSMARS is a large-scale synthetic dataset, comprising pairs of scenarios simulating urban changes, designed for training and validating change detection applications, as well as urban segmentation and building extraction tasks. The dataset simulates the terrains of two European cities: Paris and Venice, generating scenario pairs named SParis and SVenice, each accompanied by ortho-images and Digital Surface Models (DSMs). Changes between the before and after scenarios are simulated, with the latter having more buildings, less green space, and some simulated demolished buildings. To enhance similarity with real data, input images are further processed into ortho-photos and digital elevation models through a standard photogrammetric process, including different lighting conditions and other effects, such as blurred building boundaries. Reference ground truth maps are directly used for training and validation of change detection, building extraction, and urban segmentation tasks. The data is rendered at two Ground Sampling Distances (GSDs) of 30cm and 50cm. Each tile, from left to right, includes: optical image, DSM, semantic and building masks. For change detection, the difference between two events is used as the ground truth. Paper: [Reyes et al., 2023](https://www.sciencedirect.com/science/article/pii/S092427162300254X)\n\n- 2023.[**HRCUS-CD (High-Resolution Complex Urban Scene Change Detection)**](https://github.com/zjd1836/AERNet)   \nThe proposed High-Resolution Complex Urban Scene Change Detection (HRCUS-CD) dataset consists of 11,388 pairs of cropped high-resolution remote sensing images. The image size is 256 \u00d7 256 pixels with a resolution of 0.5 meters. The dataset includes over 12,000 annotated instances of changes. The data was collected in Zhuhai, China. It contains two main acquisition areas from two image sources: the first is mainly the urban built-up area, with a time span from 2019 to 2022. Considering the short time interval and the fact that this area is mostly built-up, the building changes\u2019 areas are small. The second area spans from 2010 to 2018, and contains farmland and mountains, with a small number of old civil houses and buildings in the early period, and the area of building change is large later. These two types of high-resolution RSIs focus on built-up areas and new urban areas. Paper: [Zhang et al., 2023](https://ieeexplore.ieee.org/document/10209204)\n\n- 2023.[**GVLM**](https://github.com/zxk688/GVLM)   \nThe Global Very-High-Resolution Landslide Mapping (GVLM) dataset is the first large-scale and open-source VHR landslide mapping dataset. It includes \n 17 bitemporal very-high-resolution imagery pairs with a spatial resolution of 0.59 m acquired via Google Earth service. Each sub-dataset contains a pair of bitemporal images and the corresponding ground-truth map. The landslide sites in different geographical locations have various sizes, shapes, occurrence times, spatial distributions, phenology states, and land cover types, resulting in considerable spectral heterogeneity and intensity variations in the remote sensing imagery. The GVLM dataset can be used to develop and evaluate machine/deep learning models for change detection, semantic segmentation and landslide extraction. Paper: [Zhang et al., 2023](https://www.sciencedirect.com/science/article/pii/S0924271623000242?dgcid)\n\n- 2023.[**EGY-BCD**](https://github.com/oshholail/EGY-BCD)   \nThe EGY-BCD dataset is designed to detect building changes from high-resolution satellite imagery with a resolution of 0.25 m/pixel (level 19). The dataset includes four urban and coastal areas in Egypt, collected from Google Earth over two different periods between 2015 and 2022. The dataset contains 6091 pairs of small images of size 256\u00d7256 and is randomly divided into three sets: a training set (70%), a validation set (20%), and a test set (10%). The ground-truth data for each pair of images is labeled into two categories, \"no-change\" or \"change,\" to train the proposed network. Paper: [Holail et al.2023](https://ieeexplore.ieee.org/document/10145434)\n\n- 2023.[**SI-BU dataset**](https://github.com/liaochengcsu/BCE-Net)   \nThe SI-BU dataset comprises post-phase satellite imagery captured from Google Earth (Google Inc.) in 2021 of Guiyang, Guizhou province, China, along with corresponding labels. The dataset covers an area of approximately 172 km2 and contains buildings of varying height, scale, and appearance. The images and labels were cropped into non-overlapping pairs of 512 \u00d7 512 pixels, with 3,604 pairs for training and 1,328 pairs for testing. The labels indicate four categories: background, unchanged buildings, newly constructed buildings, and removed buildings, which are assigned values of 0, 1, 2, and 3, respectively. The labels were meticulously annotated by image interpretation experts to indicate changes between the images and building masks collected from the same location in 2019. The dataset exhibits an off-nadir problem, particularly for high-rise buildings, due to the offset between building rooftops and footprints, which makes it challenging to automatically extract building changes from the dataset. Paper: [Liao et al.2023](https://arxiv.org/abs/2304.07076)\n\n- 2023.[**CNAM-CD**](https://github.com/Silvestezhou/CNAM-CD)   \nCNAM-CD is a multi-class change detection dataset that collects images of 12 different urban scenes from the past decade. The dataset selects 12 State-level New Areas in China as the study area and contains 2503 pairs of GeoTiff format images with a pixel size of 512\u00d7512. The images were captured at different times from 2013 to 2022. The data source is Google Earth, and the resolution is 0.5m. Paper: [Zhou et al.2023](https://www.mdpi.com/2072-4292/15/9/2464)\n\n- 2023.[**BANDON (Building Change Detection with Off-nadir Aerial Images Dataset)**](https://arxiv.org/abs/2301.10922)   \nThe BANDON dataset is designed for building change detection using off-nadir aerial images. It consists of 2283 image pairs from urban and rural areas with corresponding change, BT-flows, segmentation, and ST-offsets labels (test sets don't have auxiliary annotations). BANDON provides novel data for the off-nadir building change detection task, and its detailed annotations support multi-task learning in aerial images. Paper: [Pang et al.2023](https://arxiv.org/abs/2301.10922)\n\n- 2022.[**LEVIR Change Captioning (LEVIR-CC) dataset**](https://github.com/Chen-Yang-Liu/RSICC)   \nLEVIR-CC dataset contains 10077 pairs of bitemporal RS images and 50385 sentences describing the differences between images. The images of the LEVIR-CC dataset are mainly from the CD dataset LEVIR-CD. LEVIR-CC dataset may help explore models to align visual changes and language in RS images. Paper: [Liu et al.2022](https://ieeexplore.ieee.org/document/9934924)\n\n- 2022.[**DynamicEarthNet**](https://mediatum.ub.tum.de/1650201)   \nThe DynamicEarthNet dataset includes daily satellite data from January 2018 to December 2019, covering 75 areas of interest around the world with diverse land cover changes. It provides a sequence of daily revisited images for each region, as well as pixel-wise semantic labels for the first day of each month at a resolution of 1024x1024 and pixel granularity of 3 meters, which serve as ground-truth for defining land cover changes over the two-year period. Paper: [Toker A et al.2022](https://arxiv.org/abs/2203.12560)\n\n- 2022.[**Multisource built-up change (MSBC) and multisource OSCD (MSOSCD) datasets**](https://github.com/Lihy256/MSCDUnet)   \nThe datasets are made to fill the gap of built-up CD datasets including multispectral, SAR, and VHR. MSBC is labeled based on GF-2 VHR images, and the MSOSCD is reformed from an existing dataset\u2014[Onera Satellite CD(OSCD) dataset](https://ieee-dataport.org/open-access/oscd-onera-satellite-change-detection). Paper: [Li et al.2022](https://ieeexplore.ieee.org/document/9791854)\n\n- 2022.[**CLCD dataset**](https://github.com/liumency/CropLand-CD)   \nThe CLCD dataset consists of 600 pairs image of cropland change samples, with 320 pairs for training, 120 pairs for validation and 120 pairs for testing. The bi-temporal images in CLCD were collected by Gaofen-2 in Guangdong Province, China, in 2017 and 2019, respectively, with spatial resolution ranged from 0.5 to 2 m. Each group of samples is composed of two images of 512 \u00d7 512 and a corresponding binary label of cropland change. The main types of change annotated in CLCD include buildings, roads, lakes and bare soil lands, etc. Paper: [Liu et al.2022](https://ieeexplore.ieee.org/document/9780164)\n\n- 2021.[**QFabric**](https://sagarverma.github.io/qfabric)   \nQFabric is a comprehensive temporal multi-task dataset with 450,000 change polygons across 504 locations in 100 cities, using imagery from Maxar\u2019s WorldView-2 Satellite collected between January 2014 and July 2020. It includes 6 change types and 9 change status classes, and the accompanying geography and environment metadata provides valuable context for deep neural network development. Paper: [Verma S et al.2021](https://sagarverma.github.io/others/Earthvision_2021_QFabric.pdf)\n\n- 2021.[**HTCD dataset**](https://github.com/ShaoRuizhe/SUNet-change_detection)   \nThe HTCD dataset, a new Satellite-UAV heterogeneous image data set, was built using the satellite images from [Google Earth](https://www.google.com/earth/) and UAV images from [Open Aerial Map](https://map.openaerialmap.org/). The size of the satellite image is 11 K\u00d715 K pixels. While the UAV image is consisted of 15 image blocks, in total 1.38 M\u00d71.04 M pixels. The ground resolutions of them are 0.5971 m and 7.465 cm, respectively. Images and labels are all stored in GeoTiff format with location information, for the convenience of further analysis and research. Paper: [Shao et al.2021](https://www.mdpi.com/2072-4292/13/18/3750/htm)\n\n- 2021.[**Multi-modal Supervised Change Detection Data**](https://github.com/PatrickTUM/multimodalCD_ISPRS21)   \nSentinel-1 SAR data were provided on the basis of [OSCD dataset](https://ieee-dataport.org/open-access/oscd-onera-satellite-change-detection) for multimodal supervised change detection (SAR-SAR CD or Optical-SAR multi-modal CD). Paper: [Ebel et al.2021](https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLIII-B3-2021/243/2021/isprs-archives-XLIII-B3-2021-243-2021.pdf)\n\n- 2021.[**S2Looking**](https://github.com/AnonymousForACMMM/Dataset)   \nS2Looking, a building change detection dataset that contains large-scale side-looking satellite images captured at varying off-nadir angles. It consists of 5000 registered bitemporal image pairs (size of 1024*1024, 0.5 ~ 0.8 m/pixel) of rural areas throughout the world and more than 65,920 annotated change instances. It provides two label maps to separately indicate the newly built and demolished building regions for each sample in the dataset. Paper: [Shen et al.2021](https://www.mdpi.com/2072-4292/13/24/5094)\n\n- 2021.[**SYSU-CD**](https://github.com/liumency/SYSU-CD)   \nThe dataset contains 20000 pairs of 0.5-m aerial images of size 256\u00d7256 taken between the years 2007 and 2014 in Hong Kong.The main types of changes in the dataset include: (a) newly built urban buildings; (b) suburban dilation; (c) groundwork before construction; (d) change of vegetation; (e) road expansion; (f) sea construction. Paper: [Shi et al.2021](https://ieeexplore.ieee.org/document/9467555)\n\n- 2021.[**Sentinel-2 Multitemporal Cities Pairs (S2MTCP) dataset**](https://zenodo.org/record/4280482#.YBBCX-j7RhE)   \nThe S2MTCP dataset contains N = 1520 image pairs, spread over all inhabited continents, with the highest concentration of image pairs in North-America, Europe, and Asia. Bands with a spatial resolution smaller than 10 m are resampled to 10 m and images are cropped to approximately 600x600 pixels. It was created for self-supervised training. Paper: [Leenstra et al.2021](https://arxiv.org/abs/2101.08122)\n\n- 2020.[**Hi-UCD**](Hi-UCD)   \nHi-UCD focuses on urban changes and uses ultra-high resolution images to construct multi-temporal semantic changes to achieve refined change detection. The study area of Hi-UCD is a part of Tallinn, the capital of Estonia, with an area of 30km2. There are 359 image pairs in 2017-2018, 386 pairs in 2018-2019, and 548 pairs in 2017-2019, including images, semantic maps, and change maps at different times. Each image has a size of 1024 x 1024 and a spatial resolution of 0.1 m. There are 9 types of objects, including natural objects (water, grassland, woodland, bare land), artificial objects (Building,greenhouse, road, bridge), and others (change-related), basically include all types of urbanland cover in Estonia. Paper: [Tian et al.2020](https://arxiv.org/abs/2011.03247)\n\n- 2020.[**DSIFN Dataset**](https://github.com/GeoZcx/A-deeply-supervised-image-fusion-network-for-change-detection-in-remote-sensing-images/tree/master/dataset)   \nThe dataset is manually collected from Google Earth. It consists of six large bi-temporal high resolution images covering six cities (i.e., Beijing, Chengdu, Shenzhen, Chongqing, Wuhan, Xian) in China. The five large image-pairs (i.e., Beijing, Chengdu, Shenzhen, Chongqing, Wuhan) are clipped into 394 subimage pairs with sizes of 512\u00d7512. After data augmentation, a collection of 3940 bi-temporal image pairs is acquired. Xian image pair is clipped into 48 image pairs for model testing. There are 3600 image pairs in the training dataset, 340 image paris in the validation dataset, and 48 image pairs in the test dataset. Paper: [Zhang et al.2020](https://www.sciencedirect.com/science/article/abs/pii/S0924271620301532)\n\n- 2020.[**SEmantic Change detectiON Dataset (SECOND)**](http://www.captain-whu.com/PROJECT/SCD/)   \nSECOND, a well-annotated semantic change detection dataset, which collects 4662 pairs of aerial images from several platforms and sensors. These pairs of images are distributed over the cities such as Hangzhou, Chengdu, and Shanghai. Each image has size 512 x 512 and is annotated at the pixel level. SECOND focus on 6 main land-cover classes, i.e. , non-vegetated ground surface, tree, low vegetation, water, buildings, and playgrounds, that are frequently involved in natural and man-made geographical changes. Paper: [Yang et al.2020](https://arxiv.org/abs/2010.05687)\n\n\n- 2020.[**Google Dataset**](https://github.com/daifeng2016/Change-Detection-Dataset-for-High-Resolution-Satellite-Imagery)   \nThe images were acquired during the periods between 2006 and 2019, covering the suburb areas of Guangzhou City, China. To facilitate image pair generation, Google Earth service through the [BIGEMAP](http://www.bigemap.com) software was adopted to collect 19 season-varying VHR images pairs with three bands of red, green, and blue, a spatial resolution of 0.55 m, and the size ranging from 1006\u00d71168 pixels to 4936\u00d75224 pixels. The annotation is focused on buildings. Paper: [Peng et al.2020](https://ieeexplore.ieee.org/document/9161009)\n\n- 2020.[**LEVIR building Change Detection (LEVIR-CD) Dataset**](https://justchenhao.github.io/LEVIR/)   \nLEVIR-CD consists of 637 very high-resolution (VHR, 0.5m/pixel) Google Earth image patch pairs with a size of 1024 \u00d7 1024 pixels. These bitemporal images with time span of 5 to 14 years have significant land-use changes, especially the construction growth. LEVIR-CD covers various types of buildings, such as villa residences, tall apartments, small garages and large warehouses. The fully annotated LEVIR-CD contains a total of 31,333 individual change building instances. LEVIR-CD+ can be found in this [page](https://github.com/AnonymousForACMMM/Dataset). Paper: [Chen et al.2020](https://www.mdpi.com/2072-4292/12/10/1662)\n\n- 2019.[**High Resolution Semantic Change Detection (HRSCD) Dataset**](https://ieee-dataport.org/open-access/hrscd-high-resolution-semantic-change-detection-dataset)   \nThis dataset contains 291 coregistered image pairs of RGB aerial images from IGS's BD ORTHO database. Pixel-level change and land cover annotations are provided, generated by rasterizing Urban Atlas 2006, Urban Atlas 2012, and Urban Atlas Change 2006-2012 maps. Paper: [Daudt et al.2019](https://www.sciencedirect.com/science/article/pii/S1077314219300992)\n  \n- 2019.[**Wuhan multi-temperature scene (MtS-WH) Dataset**](http://sigma.whu.edu.cn/newspage.php?q=2019_03_26)   \nThe dataset is mainly used for theoretical research and verification of scene change detection methods. It consists of two large-size VHR images, which have a size of 7200x6000 and are respectively acquired by IKONOS sensors in Feb 2002 and Jun 2009. The images cover the Hanyang District, Wuhan City, China and contain 4 spectral bands (Blue, Green, Red, and Near-Infrared). The spatial resolution of the images is 1m after fusion of the pan and multispectral images by the Gram\u2013Schmidt algorithm. For a discussion of this dataset, please refer to [#3](https://github.com/wenhwu/awesome-remote-sensing-change-detection/issues/3). Paper: [Wu et al.2017](https://ieeexplore.ieee.org/document/7817860)\n\n- 2018.[**WHU Building change detection Dataset**](https://study.rsgis.whu.edu.cn/pages/download/building_dataset.html)   \nThe dataset contains two aerial images (0.2m/pixel, 15354\u00d732507) and provides a change vector, a change raster map, and two corresponding building vectors of these two aerial images. Paper: [Ji et al.2018](https://ieeexplore.ieee.org/document/8444434)\n\n- 2018.[**Synthetic images and real season-varying remote sensing images**](https://drive.google.com/file/d/1GX656JqqOyBi_Ef0w65kDGVto-nHrNs9/edit)   \nThis dataset has three types: synthetic images without objects relative shift, synthetic images with small relative shift of objects, real season-varying remote sensing images (obtained by Google Earth). The real season-varying remote sensing images have 16000 image sets with image size 256x256 pixels (10000 train sets and 3000 test and validation sets) and a spatial resolution of 3 to 100 cm/px. For a discussion of this dataset, please refer to [#5](https://github.com/wenhwu/awesome-remote-sensing-change-detection/issues/5). Paper: [Lebedev et al.2018](https://www.int-arch-photogramm-remote-sens-spatial-inf-sci.net/XLII-2/565/2018/isprs-archives-XLII-2-565-2018.pdf)\n\n- 2018.[**Onera Satellite Change Detection Dataset**](https://ieee-dataport.org/open-access/oscd-onera-satellite-change-detection)   \nThis dataset addresses the issue of detecting changes between satellite images from different dates. It comprises 24 pairs of multispectral images taken from the Sentinel-2 satellites between 2015 and 2018. Locations are picked all over the world, in Brazil, USA, Europe, Middle-East and Asia. For each location, registered pairs of 13-band multispectral satellite images obtained by the Sentinel-2 satellites are provided. Images vary in spatial resolution between 10m, 20m, and 60m. Paper: [Daudt et al.2018](https://ieeexplore.ieee.org/document/8518015)\n\n- 2011.[**The Aerial Imagery Change Detection (AICD) dataset**](https://computervisiononline.com/dataset/1105138664)   \nThis dataset contains synthetic aerial images with artificial changes generated with a rendering engine. It contains 1000 pairs of 800x600 images, each pair consisting of one reference image and one test image, and the 1000 corresponding 800x600 ground truth masks. Paper: [Bourdis et al.2011](https://ieeexplore.ieee.org/document/6050150)\n\n- 2008.[**SZTAKI AirChange Benchmark set**](http://web.eee.sztaki.hu/remotesensing/airchange_benchmark.html)   \nThis dataset contains 13 aerial image pairs of size 952x640 and resolution 1.5m/pixel and binary change masks (drawn by hand). Each record contains a pair of preliminary registered input images and a mask of the 'relevant' changes. The input images are taken with 5, 7 resp. 23 years of time differences. During the generation of the change mask, we have considered the following differences as relevant changes: (a) new built-up regions (b) building operations (c) planting of large group of trees (d) fresh plow-land (e) groundwork before building over. Note that the ground truth does NOT contain change classification, only binary change-no change decision for each pixel. Paper: [Benedek et al.2008](https://ieeexplore.ieee.org/document/5169964)\n\n### Without Label\n\n- [Planet Disaster Datasets](https://www.planet.com/disasterdata/datasets/)   \nPlanet will make PlanetScope imagery available to the public during a select disaster event.\n\n- [Maxar's Open Data Program](https://www.maxar.com/open-data)   \nMaxar will release open imagery (worldview-3 or other) for select sudden onset major crisis events, including pre-event imagery, post-event imagery, and a crowdsourced damage assessment.\n\n- [French National Institute of Geographical and Forest Information (IGN),BD ORTHO](http://professionnels.ign.fr/bdortho)   \nThe datasets are mosaics of aerial images taken by the French National Institute of Geographical and Forest Information (IGN). They come from a database named BD ORTHO which contains orthorectified aerial images of several regions of France from different years at a resolution of 20 cm or 50 cm per pixel. \n\n- [LINZ DATA SERVICE](https://data.linz.govt.nz/)   \nThe New Zealand Land Information Services website provides multi-temporal aerial images of some New Zealand cities, all of which have a resolution of over 1m.\n\n- [USGS EarthExplorer](https://earthexplorer.usgs.gov)   \nAn epic level database, which can provide multi-temporal\uff0cmulti-sensor and multi-resolution data.\n\n## Hyperspectral\n\n- 2018.[Hyperspectral Change Detection Dataset](https://citius.usc.es/investigacion/datasets/hyperspectral-change-detection-dataset)   \nThis dataset can be used to perform change detection techniques in multi-temporal hyperspectral images. It includes two different hyperspectral scenes from the AVIRIS sensor: The Santa Barbara scene, taken on the years 2013 and 2014 with the AVIRIS sensor over the Santa Barbara region (California) whose spatial dimensions are 984 x 740 pixels and includes 224 spectral bands. The Bay Area scene, taken on the years 2013 and 2015 with the AVIRIS sensor surrounding the city of Patterson (California) whose spatial dimensions are 600 x 500 pixels and includes 224 spectral bands.\nIt also includes a hyperspectral scene from the HYPERION sensor: The Hermiston city scene, taken on the years 2004 and 2007 with the HYPERION sensor over the Hermiston City area (Oregon) whose spatial dimensions are 390 x 200 pixels and includes 242 spectral bands. 5 types of changes related to crop transitions are identified in this scene. Paper: [L\u00f3pez-Fandi\u00f1o et al.2018](https://ieeexplore.ieee.org/document/8518338)\n\n- 2018.[GETNET](https://drive.google.com/file/d/1cWy6KqE0rymSk5-ytqr7wM1yLMKLukfP/view)   \nThis dataset has two hyperspectral images, which were acquired on May 3, 2013, and December 31, 2013, respectively in Jiangsu province, China. It has a size of 463\u00d7241 pixels, with 198 bands available after noisy band removal. In the ground-truth map, white pixels represent changed portions and black pixels mean unchanged parts. Paper: [Wang et al.2018](https://ieeexplore.ieee.org/document/8418840/?denied=)\n\n## 3D\n\n- 2023.[3DCD Dataset](https://sites.google.com/uniroma1.it/3dchangedetection/home-page?pli=1)   \nThe 3DCD Dataset is designed to facilitate the development of deep learning algorithms that can infer 3D CD maps from remote sensing optical bitemporal images alone, without the need for Digital Elevation Models (DEMs). The dataset comprises pairs of optical images acquired in 2010 and 2017, corresponding 2D and 3D CD maps in raster format (.tiff), and pairs of Digital Surface Models (DSMs) covering the same area and years in the same format (.tiff). Paper: [Marsocci V et al.2023](https://www.sciencedirect.com/science/article/pii/S0924271622003240)\n\n- 2021.[URB3DCD](https://ieee-dataport.org/open-access/urb3dcd-urban-point-clouds-simulated-dataset-3d-change-detection)   \nThe dataset is based on LoD2 models of [the first and second districts of Lyon](https://geo.data.gouv.fr/datasets/0731989349742867f8e659b4d70b707612bece89), France. To conduct fair qualitative and quantitative evaluation of point clouds change detection techniques. This first version of the dataset is composed of point clouds at a challenging low resolution of around 0.5 points/meter\u00b2. Paper: [de G\u00e9lis et al.2021](https://www.mdpi.com/2072-4292/13/13/2629)\n\n# Code\n\n## Multispectral\n\n### Traditional Method\n\n- [Kondmann L, Toker A, Saha S, et al. SiROC: Spatial Context Awareness for Unsupervised Change Detection in Optical Satellite Images](https://github.com/lukaskondmann/SiROC). TGRS 2021\n\n- [Lv Z, Wang F J, Liu T, et al. Novel Automatic Approach for Land Cover Change Detection by Using VHR Remote Sensing Images](https://github.com/TongfeiLiu/ASEA-CD). GRSL 2021\n\n- 2019.[Bobholamovic/ChangeDetectionToolbox](https://github.com/Bobholamovic/ChangeDetectionToolbox)\n\n- 2019.[Canty M J. Image Analysis, Classification and Change Detection in Remote Sensing (Fourth Revised Edition)](https://github.com/mortcanty/CRC4Docker)\n\n- 2017.[Canty M J. Change Detection with Google Earth Engine Imagery](https://github.com/mortcanty/earthengine)\n\n- 2014.[Canty M J. Image Analysis, Classification and Change Detection in Remote Sensing (Third Revised Edition)](https://github.com/mortcanty/CRCPython)\n\n- [Zhu Z, Woodcock C E, et al. Algorithm developed for Continuous Change Detection and Classification (CCDC) of land cover using all available Landsat data](https://github.com/GERSL/CCDC)\n\n- [Li X, Liu X, Liang X, et al. Geographical Simulation and Optimization System (GeoSOS)](https://www.geosimulation.cn/index.html)\n\n- Implementation of \" [2009.Celik T. Unsupervised change detection in satellite images using principal component analysis and k-means clustering](https://ieeexplore.ieee.org/abstract/document/5196726/) \".  \n[Matlab](https://github.com/rulixiang/ChangeDetectionPCAKmeans), [Python](https://github.com/abhijeet3922/Change-Detection-in-Satellite-Imagery)\n\n- [Nielsen A A.The Regularized Iteratively Reweighted Multivariate Alteration Detection (IR-MAD)](http://people.compute.dtu.dk/alan/software.html). TIP 2007\n\n### Deep Learning\n\n#### 2D\n\n- [Ding L, Zhu K, Peng D, et al. Adapting Segment Anything Model for Change Detection in HR Remote Sensing Images](https://github.com/ggsDing/SAM-CD). arXiv 2023\n\n- [Zheng Z, Tian S, Ma A, et al. Scalable Multi-Temporal Remote Sensing Change Data Generation via Simulating Stochastic Change Process](https://github.com/Z-Zheng/Changen). ICCV 2023\n\n- [Bernhard M, Strau\u00df N, Schubert M. MapFormer: Boosting Change Detection by Using Pre-change Information](https://github.com/mxbh/mapformer). ICCV 2023 \n\n- [Mall U, Hariharan B, Bala K. Change-Aware Sampling and Contrastive Learning for Satellite Images](https://github.com/utkarshmall13/caco). CVPR 2023\n\n- [Xing Y, Jiang J, Xiang J, et al. LightCDNet: Lightweight Change Detection Network Based on VHR Images](https://github.com/NightSongs/LightCDNet). GRSL 2023\n\n- [Lei T, Geng X, Ning H, et al. Ultralightweight Spatial\u2013Spectral Feature Cooperation Network for Change Detection in Remote Sensing Images](https://github.com/SUST-reynole/USSFC-Net). TGRS 2023\n\n- [Li Z, Tang C, Liu X, et al. Lightweight Remote Sensing Change Detection with Progressive Feature Aggregation and Supervised Attention](https://github.com/guanyuezhen/A2Net). TGRS 2023\n\n- [Feng Y, Jiang J, Xu H, et al. Change Detection on Remote Sensing Images using Dual-branch Multi-level Inter-temporal Network](https://github.com/ZhengJianwei2/DMINet). TGRS 2023\n\n- [Seo M, Lee H, Jeon Y, et al. Self-Pair: Synthesizing Changes from Single Source for Object Change Detection in Remote Sensing Imagery](https://github.com/seominseok0429/Self-Pair-for-Change-Detection). WACV2023\n\n- [Fang S, Li K, Li Z. Changer: Feature Interaction is What You Need for Change Detection](https://github.com/likyoo/open-cd/tree/main/configs/changer). TGRS 2023\n\n- [Chen H, Pu F, Yang R, et al. RDP-Net: Region detail preserving network for change detection](https://github.com/Chnja/RDPNet). TGRS 2022\n\n- [Cao Y, Huang X. A full-level fused cross-task transfer learning method for building change detection using noise-robust pretrained networks on crowdsourced labels](https://github.com/lauraset/FFCTL). RSE 2022\n\n- [Chen H, Li W, Chen S, et al. Semantic-aware Dense Representation Learning for Remote Sensing Image Change Detection](https://github.com/justchenhao/SaDL_CD). TGRS 2022\n\n- [Codegoni A, Lombardi G, Ferrari A. TINYCD: A (Not So) Deep Learning Model For Change Detection](https://github.com/AndreaCodegoni/Tiny_model_4_CD).  Neural Computing and Applications 2022\n\n- [Pei G, Zhang L. Feature Hierarchical Differentiation for Remote Sensing Image Change Detection](https://github.com/ZSVOS/FHD). GRSL 2022\n\n- 2022.[likyoo/Open-CD](https://github.com/likyoo/open-cd): Open-CD is an open source change detection toolbox based on a series of open source general vision task tools.\n\n- [Shi N, Chen K, Zhou G. A Divided Spatial and Temporal Context Network for Remote Sensing Change Detection](https://github.com/shinianzhihou/ChangeDetection#). JSTARS 2022\n\n- [Liu M, Chai Z, Deng H, et al. A CNN-transformer Network with Multi-scale Context Aggregation for Fine-grained Cropland Change Detection](https://github.com/liumency/CropLand-CD). JSTARS 2022\n\n- [Liu J, Xuan W, Gan Y, et al. An End-to-end Supervised Domain Adaptation Framework for Cross-Domain Change Detection](https://github.com/Perfect-You/SDACD). Pattern Recognition 2022   \n\n- 2022.[PaddleRS](https://github.com/PaddlePaddle/PaddleRS): Awesome Remote Sensing Toolkit based on PaddlePaddle\n\n- [Ding L, Guo H, Liu S, et al. Bi-temporal semantic reasoning for the semantic change detection in HR remote sensing images](https://github.com/ggsDing/Bi-SRNet). TGRS 2022\n\n- [Bandara W G C, Nair N G, Patel V M. DDPM-CD: Remote Sensing Change Detection using Denoising Diffusion Probabilistic Models](https://github.com/wgcban/ddpm-cd). arXiv 2022\n\n- [Bandara W G C, Patel V M. Revisiting Consistency Regularization for Semi-supervised Change Detection in Remote Sensing Images](https://github.com/wgcban/SemiCD). arXiv 2022\n\n- [Bandara W G C, Patel V M. A Transformer-Based Siamese Network for Change Detection](https://github.com/wgcban/ChangeFormer). IGARSS 2022\n\n- [Saha S, Ebel P, Zhu X X. Self-supervised multisensor change detection](https://gitlab.lrz.de/ai4eo/cd/-/tree/main/sarOpticalMultisensorTgrs2021). TGRS 2022\n\n- [Chen P, Hong D, Chen Z, et al. FCCDN: Feature Constraint Network for VHR Image Change Detection](https://github.com/chenpan0615/FCCDN_pytorch). ISPRS P&RS 2022\n\n- 2021.[Bobholamovic/CDLab](https://github.com/Bobholamovic/CDLab): Yet another repository for developing and benchmarking deep learning-based change detection methods\n\n- 2021.[shinianzhihou/ChangeDetection](https://github.com/shinianzhihou/ChangeDetection): A framework for change detection using PyTorch\n\n- [Shi Q, Liu M, Li S, et al. A Deeply Supervised Attention Metric-Based Network and an Open Aerial Image Dataset for Remote Sensing Change Detection](https://github.com/liumency/DSAMNet). TGRS 2021\n\n- [Shao R, Du C, Chen H, et al. SUNet: Change Detection for Heterogeneous Remote Sensing Images from Satellite and UAV Using a Dual-Channel Fully Convolution Network](https://github.com/ShaoRuizhe/SUNet-change_detection). Remote Sensing 2021\n\n- [Diakogiannis F I, Waldner F, Caccetta P. Looking for change? Roll the Dice and demand Attention](https://github.com/feevos/ceecnet). Remote Sensing 2021\n\n- [Papadomanolaki M, Vakalopoulou M, Karantzalos K. A Deep Multi-Task Learning Framework Coupling Semantic Segmentation and Fully Convolutional LSTM Networks for Urban Change Detection](https://github.com/mpapadomanolaki/multi-task-L-UNet). TGRS 2021\n\n- [Zheng Z, Zhong Y, Wang J, et al. Building damage assessment for rapid disaster response with a deep object-based semantic change detection framework: from natural disasters to man-made disasters](https://github.com/Z-Zheng/ChangeOS). RSE 2021\n\n- [Xu J, Luo C, Chen X, et al. Remote Sensing Change Detection Based on Multidirectional Adaptive Feature Fusion and Perceptual Similarity](https://github.com/wzjialang/MFPNet). Remote Sensing 2021\n\n- [Zhang H, Lin M, Yang G, et al. ESCNet: An End-to-End Superpixel-Enhanced Change Detection Network for Very-High-Resolution Remote Sensing Images](https://github.com/Bobholamovic/ESCNet). TNNLS 2021\n\n- [Ma\u00f1as O, Lacoste A, Giro-i-Nieto X, et al. Seasonal Contrast: Unsupervised Pre-Training from Uncurated Remote Sensing Data](https://github.com/ElementAI/seasonal-contrast). ICCV 2021\n\n- [Zheng Z, Ma A, Zhang L, et al. Change is Everywhere: Single-Temporal Supervised Object Change Detection for High Spatial Resolution Remote Sensing Imagery](https://github.com/Z-Zheng/ChangeStar). ICCV 2021\n\n- [Liu M, Shi Q, Marinoni A, et al. Super-resolution-based Change Detection Network with Stacked Attention Module for Images with Different Resolutions](https://github.com/liumency/SRCDNet). TGRS 2021\n\n- [Chen H, Qi Z, Shi Z. Remote Sensing Image Change Detection with Transformers](https://github.com/justchenhao/BIT_CD).TGRS 2021   \n\n- [Chen H, Li W, Shi Z. Adversarial Instance Augmentation for Building Change Detection in Remote Sensing Images](https://github.com/justchenhao/IAug_CDNet).TGRS 2021 \n\n- [Fang S, Li K, Shao J, et al. SNUNet-CD: A Densely Connected Siamese Network for Change Detection of VHR Images](https://github.com/likyoo/Siam-NestedUNet). GRSL 2021 \n\n- 2020.[ChenHongruixuan/ChangeDetectionRepository](https://github.com/ChenHongruixuan/ChangeDetectionRepository)\n\n- 2020.[llu025/Heterogeneous_CD](https://github.com/llu025/Heterogeneous_CD)\n\n- [Daudt R C, Le Saux B, Boulch A. Fully convolutional siamese networks for change detection](https://github.com/rcdaudt/fully_convolutional_change_detection). ICIP 2018\n\n#### 3D\n- [Marsocci V, Coletta V, Ravanelli R, et al. Inferring 3D change detection from bitemporal optical images](https://github.com/VMarsocci/3DCD). ISPRS P&RS 2023\n- 2023.[de G\u00e9lis I, Lef\u00e8vre S, Corpetti T. Siamese KPConv: 3D multiple change detection from raw point clouds using deep learning](https://github.com/IdeGelis/torch-points3d-SiameseKPConv). ISPRS P&RS 2023\n\n## SAR\n- [Alatalo J, Sipola T, Rantonen M. Improved Difference Images for Change Detection Classifiers in SAR Imagery Using Deep Learning](https://github.com/janne-alatalo/sar-change-detection). TGRS 2023\n- [Qu X, Gao F, Dong J, et al. Change Detection in Synthetic Aperture Radar Images Using a Dual-Domain Network](https://github.com/summitgao/SAR_CD_DDNet). GRSL 2022\n\n## Hyperspectral\n- [Wang Y, Hong D, Sha J, et al. Spectral\u2013spatial\u2013temporal transformers for hyperspectral image change detection](https://github.com/yanhengwang-heu/IEEE_TGRS_SSTFormer). TGRS 2022\n- [Hu M, Wu C, Zhang L, et al. Hyperspectral anomaly change detection based on autoencoder](https://github.com/meiqihu/ACDA). JSTARS 2021\n\n\n# Contest   \n\n**Please note that some of the datasets in these competitions are publicly available, such as xView2 and SpaceNet7.**\n\n- [**2023 \u201c\u5409\u6797\u4e00\u53f7\u201d\u676f\u536b\u661f\u9065\u611f\u5e94\u7528\u9752\u5e74\u521b\u65b0\u521b\u4e1a\u5927\u8d5b-\u57fa\u4e8e\u9ad8\u5206\u8fa8\u7387\u536b\u661f\u5f71\u50cf\u7684\u8015\u5730\u53d8\u5316\u68c0\u6d4b**](https://www.jl1mall.com/contest/match/info?id=1645664411716952066) *(\u957f\u5149\u536b\u661f, 2023\u5e745\u6708)*   \n\u8015\u5730\u53d8\u5316\u68c0\u6d4b\u5b58\u5728\u53d8\u5316\u7c7b\u578b\u591a\u3001\u53d8\u5316\u76ee\u6807\u5c0f\u7684\u68c0\u6d4b\u96be\u70b9\uff0c\u56e0\u6b64\u9700\u8981\u7814\u53d1\u4e00\u79cd\u57fa\u4e8e\u9ad8\u5206\u8fa8\u7387\u9065\u611f\u5f71\u50cf\u7684\u8015\u5730\u53d8\u5316\u68c0\u6d4b\u7b97\u6cd5\uff0c\u63d0\u9ad8\u8015\u5730\u53d8\u5316\u68c0\u6d4b\u4e2d\u5c0f\u76ee\u6807\u7684\u53ec\u56de\u7387\u548c\u8015\u5730\u53d8\u5316\u7c7b\u578b\u7684\u5206\u7c7b\u51c6\u786e\u7387\uff0c\u63a8\u52a8\u7b97\u6cd5\u5728\u201c\u975e\u519c\u5316\u201d\u3001\u8015\u5730\u4fdd\u62a4\u7b49\u5b9e\u9645\u9700\u6c42\u4e2d\u7684\u5e94\u7528\u3002\u6570\u636e: \u5409\u6797\u4e00\u53f7\uff0c\u5206\u8fa8\u7387\u4f18\u4e8e0.75\u7c73\u3002\u7c7b\u522b\u63cf\u8ff0\uff1a\u8015\u5730\u53d8\u4e3a\u9053\u8def\uff0c\u8015\u5730\u53d8\u4e3a\u6797\u8349\uff0c\u8015\u5730\u53d8\u4e3a\u5efa\u7b51\uff0c\u8015\u5730\u53d8\u4e3a\u5176\u4ed6\uff0c\u9053\u8def\u53d8\u4e3a\u8015\u5730\uff0c\u6797\u8349\u53d8\u4e3a\u8015\u5730\uff0c\u5efa\u7b51\u53d8\u4e3a\u8015\u5730\uff0c\u5176\u4ed6\u53d8\u4e3a\u8015\u5730\uff0c\u975e\u201c\u8015\u5730\u53d8\u5316\u201d\u53d8\u5316\u533a\u57df\u3002\u56fe\u50cf\u5c3a\u5bf8\uff1a256\u00d7256\u50cf\u7d20\u3002\u521d\u8d5b\u6570\u636e\u91cf\uff1a\u5171\u8ba18000\u4f59\u7ec4\uff0c\u8bad\u7ec3\u96c66000\u4f59\u7ec4,\u6bcf\u7ec4\u5305\u542b2\u4e2a\u65f6\u76f8\u5f71\u50cf\u53ca\u6807\u7b7e\uff1b\u6d4b\u8bd5\u96c62000\u4f59\u7ec4,\u6bcf\u7ec4\u5305\u542b2\u4e2a\u65f6\u76f8\u5f71\u50cf\u3002\n\n- [**2022 The SpaceNet 8 Flood Detection Challenge**](https://medium.com/@SpaceNet_Project/the-spacenet-8-flood-detection-challenge-dataset-and-algorithmic-baseline-release-e0c9f5a44154) *(SpaceNet, Maxar, Jul 2022)*   \nThree areas of interest (AOIs) were selected for the dataset consisting of 12 Maxar satellite images of both pre- and post-flooding event imagery. Along with the imagery, hand labeled building footprints, road and flood attributes are provided for training and scoring. The AOIs include Germany with flooding from heavy rains in July 2021, Louisiana following Hurricane Ida in August 2021, and a \u201cmystery\u201d location that will be used to test the top 10 algorithms from the public leaderboard for final scoring after the challenge has concluded. Baseline: [SpaceNetChallenge/SpaceNet8](https://github.com/SpaceNetChallenge/SpaceNet8). Paper: [H\u00e4nsch, Ronny, et al.2022](https://openaccess.thecvf.com/content/CVPR2022W/EarthVision/papers/Hansch_SpaceNet_8_-_The_Detection_of_Flooded_Roads_and_Buildings_CVPRW_2022_paper.pdf).\n\n- **2021 \u201c\u6607\u817e\u676f\u201d\u9065\u611f\u5f71\u50cf\u667a\u80fd\u5904\u7406\u7b97\u6cd5\u5927\u8d5b-\u8015\u5730\u5efa\u7b51\u7269\u53d8\u5316\u68c0\u6d4b** *(\u6b66\u6c49\u5927\u5b66, 2021\u5e749\u6708)*   \n\u901a\u8fc7\u524d\u540e\u4e24\u65f6\u76f8\u7684\u9065\u611f\u5f71\u50cf\uff0c\u63d0\u53d6\u51fa\u5730\u7269\u53d1\u751f\u53d8\u5316\u7684\u50cf\u5143\u5e76\u8d4b\u4e88\u53d8\u5316\u6807\u7b7e\u3002 \u4f9d\u636e\u6240\u8ff0\u5730\u7269\u53d8\u5316\u6807\u51c6\uff0c\u4ee5\u8015\u5730-\u5efa\u7b51/\u52a8\u571f\u7684\u50cf\u7d20\u7ea7\u53d8\u5316\u68c0\u6d4b\u4e3a\u76ee\u6807\u3002\u6570\u636e\u4e3a1-2\u7c73\u5206\u8fa8\u7387\u5149\u5b66\u9065\u611f\u5f71\u50cf\uff0c6000+\u5f20\u9065\u611f\u5f71\u50cf\u53d8\u5316\u68c0\u6d4b\u6837\u672c\u6570\u636e(\u6309512 X 512\u5927\u5c0f\u6298\u7b97)\u3002\u6807\u7b7e\u683c\u5f0f\u4e3a\u5355\u901a\u9053\u7684png\uff0c\u6bcf\u4e2a\u50cf\u7d20\u7684\u6807\u7b7e\u503c\u7531\u4e00\u4e2a\u6570\u503c\u8868\u793a\uff0c \u4f7f\u7528\u2018uint8\u2019\u6570\u636e\u7c7b\u578b\u5b58\u50a8\uff0c\u8be5\u6570\u503c\u8868\u793a\u662f\u5426\u4e3a\u53d8\u5316\uff0c\u201c0\u201d\u4ee3\u8868\u672a\u53d8\u5316\uff0c\u201c1\u201d\u4ee3\u8868\u53d8\u5316\u3002Top4\u89e3\u51b3\u65b9\u6848\u8be6\u89c1[WangZhenqing-RS/2021rsipac_changeDetection_TOP4](https://github.com/WangZhenqing-RS/2021rsipac_changeDetection_TOP4)\uff0cTop5\u89e3\u51b3\u65b9\u6848\u8be6\u89c1[78666621/2021rsipac_changeDetection_TOP5](https://github.com/78666621/2021rsipac_changeDetection_TOP5)  \n\n- [**2021 \u9065\u611f\u56fe\u50cf\u667a\u80fd\u89e3\u8bd1\u6280\u672f\u6311\u6218\u8d5b-\u5efa\u7b51\u7269\u53d8\u5316\u68c0\u6d4b**](https://captain-whu.github.io/PRCV2021_RS/index.html) *(\u6b66\u6c49\u5927\u5b66, \u822a\u5929\u5b8f\u56fe. 2021\u5e748\u6708)*   \n\u672c\u7ade\u8d5b\u6570\u636e\u96c6\u4e3b\u8981\u5305\u542b\u6d89\u53ca\u5efa\u7b51\u7269\u7684\u5730\u7269\u53d8\u5316\u3002\u5168\u90e8\u56fe\u50cf\u6570\u636e\u517110000\u5bf9\uff08\u8bad\u7ec3\u96c6\uff1a6000\u5bf9\u56fe\u50cf\uff0c\u9a8c\u8bc1\u96c6\uff1a2000\u5bf9\u56fe\u50cf\uff0c\u6d4b\u8bd5\u6837\u672c\uff1a2000\u5bf9\u56fe\u50cf\uff09\uff0c\u5c3a\u5bf8\u4e3a512 x 512\uff0c\u4e3b\u8981\u5206\u5e03\u4e8e\u5317\u4eac\u3001\u4e0a\u6d77\u3001\u5e7f\u5dde\u4ee5\u53ca\u676d\u5dde\u7b49\u57ce\u5e02\u3002\u90e8\u5206\u6570\u636e\u6e90\u81ea[SECOND](http://www.captain-whu.com/PROJECT/SCD/)\u6570\u636e\u96c6\u3002\u7b2c\u4e8c\u540d\u89e3\u51b3\u65b9\u6848\u8be6\u89c1[businiaoo/PRCV2021-Change-Detection-Contest-2nd-place-Solution](https://github.com/businiaoo/PRCV2021-Change-Detection-Contest-2nd-place-Solution), \u7b2c\u4e09\u540d\u89e3\u51b3\u65b9\u6848\u8be6\u89c1[likyoo/PRCV2021_ChangeDetection_Top3](https://github.com/likyoo/PRCV2021_ChangeDetection_Top3)\u3002\n\n- [**2021 \u7b2c\u4e94\u5c4a\u201c\u4e2d\u79d1\u661f\u56fe\u676f\u201d\u56fd\u9645\u9ad8\u5206\u9065\u611f\u56fe\u50cf\u89e3\u8bd1\u5927\u8d5b-\u9ad8\u5206\u8fa8\u7387\u53ef\u89c1\u5149\u56fe\u50cf\u4e2d\u5efa\u7b51\u7269\u666e\u67e5\u4e0e\u53d8\u5316\u68c0\u6d4b**](http://gaofen-challenge.com/challenge) *(\u4e2d\u56fd\u79d1\u5b66\u9662\u7a7a\u5929\u4fe1\u606f\u521b\u65b0\u7814\u7a76\u9662. 2021\u5e748\u6708)*    \n\u9ad8\u5206\u4e8c\u53f7\u3001\u5409\u6797\u4e00\u53f7\u5149\u5b66\u6570\u636e\uff0c\u5206\u8fa8\u7387\u4f18\u4e8e1m\u3002\u6bcf\u5e45\u56fe\u50cf\u5bf9\u5efa\u7b51\u7269\u8fdb\u884c\u50cf\u7d20\u7ea7\u6807\u6ce8\uff0c\u540c\u4e00\u65f6\u76f8\u6570\u636e\u5bf9\u53d8\u5316\u7684\u5efa\u7b51\u7269\u533a\u57df\u8fdb\u884c\u50cf\u7d20\u7ea7\u6807\u6ce8\u3002\u5efa\u7b51\u7269\u63d0\u53d6\u7c7b\u522b\uff1a\u5efa\u7b51\u7269\u548c\u80cc\u666f\uff0c\u53d8\u5316\u68c0\u6d4b\u7c7b\u522b\uff1a\u53d8\u5316\u7684\u5efa\u7b51\u533a\u57df\u548c\u975e\u53d8\u5316\u7684\u5efa\u7b51\u533a\u57df\u3002\n\n- [**2021 \u6167\u773c\u201c\u5929\u667a\u676f\u201d\u4eba\u5de5\u667a\u80fd\u6311\u6218\u8d5b-\u53ef\u89c1\u5149\u5efa\u7b51\u667a\u80fd\u53d8\u5316\u68c0\u6d4b**](https://www.rsaicp.com/portal/contestDetail?id=1&tab=rule) *(\u5317\u4eac\u5e02\u9065\u611f\u4fe1\u606f\u7814\u7a76\u6240\uff0c\u4e2d\u56fd\u79d1\u5b66\u9662\u4eba\u5de5\u667a\u80fd\u521b\u65b0\u7814\u7a76\u9662. 2021\u5e746\u6708)*    \n\u6bcf\u7ec4\u6570\u636e\u5305\u542b\u524d\u65f6\u76f8\u9065\u611f\u56fe\u50cf\uff0c\u540e\u65f6\u76f8\u9065\u611f\u56fe\u50cf\u4ee5\u53ca\u5bf9\u5e94\u7684\u5efa\u7b51\u53d8\u5316\u6807\u7b7e\u56fe\u3002\u5f71\u50cf\u683c\u5f0f\u4e3apng\uff0c\u5305\u542bR\u3001G\u3001B\u4e09\u4e2a\u6ce2\u6bb5\uff0c\u5f71\u50cf\u5c3a\u5bf8\u4e3a1024 X 1024\u50cf\u7d20\uff0c\u5206\u8fa8\u7387\u4e3a0.5~0.7\u7c73\u3002\u6807\u7b7e\u56fe\u4e0e\u56fe\u50cf\u7b49\u5927\uff0c\u5176\u4e2d (0,0,0) \u4ee3\u8868\u6ca1\u6709\u5efa\u7b51\u53d8\u5316\uff0c(0,0,255) \u4ee3\u8868\u5efa\u7b51\u589e\u52a0\uff0c(255,0,0) \u4ee3\u8868\u5efa\u7b51\u51cf\u5c11\u3002\n\n- [**2021 DynamicEarthNet Challenge**](http://www.classic.grss-ieee.org/earthvision2021/challenge.html) *(TUM, DLR, panet. Mar 2021)*    \nThe challenge consists of two tracks (**Unsupervised Binary Land Cover Change Detection** and **Weakly-Supervised Multi-Class Change Detection**) in which participants are tasked to detect multi-temporal changes with few or no training labels. The first solution can be found [solcummings/earthvision2021-weakly-supervised](https://github.com/solcummings/earthvision2021-weakly-supervised).\n\n- [**2021 IEEE GRSS Data Fusion Contest: Track MSD (Multitemporal Semantic Change Detection)**](https://www.grss-ieee.org/community/technical-committees/2021-ieee-grss-data-fusion-contest-track-msd/) *(GRSS, Microsoft. Jan 2021)*   \nThe task of Track MSD is to create bitemporal high resolution land cover maps using only low-resolution and noisy land cover labels for training. Such a scenario is often encountered around the world, as the proliferation of new sensors with either high spatial resolution (submeter) or high temporal resolution (weekly or even daily) remains unmatched by equally rich label data. Instead, detecting change would have to rely on the analysis of a sequence of input images in an unsupervised manner or with aid of weak, noisy, and outdated labels. Paper: [Li Z et al. 2022](https://ieeexplore.ieee.org/document/9690575).\n\n- [**2020 SpaceNet 7: Multi-Temporal Urban Development Challenge**](https://medium.com/the-downlinq/the-spacenet-7-multi-temporal-urban-development-challenge-dataset-release-9e6e5f65c8d5) *(CosmiQ Works, Planet. Aug 2020)*   \nIn this challenge, participants will identify and track buildings in satellite imagery time series collected over rapidly urbanizing areas. The competition centers around a new open source dataset of Planet satellite imagery mosaics, which will include 24 images (one per month) covering ~100 unique geographies. The dataset will comprise 40,000 km2 of imagery and exhaustive polygon labels of building footprints in the imagery, totaling over 3M individual annotations. Challenge participants will be asked to track building construction over time, thereby directly assessing urbanization. For details about the solution, see [SpaceNetChallenge/SpaceNet7_Multi-Temporal_Solutions](https://github.com/SpaceNetChallenge/SpaceNet7_Multi-Temporal_Solutions).\n\n- [**2020 \u5546\u6c64\u79d1\u6280\u9996\u5c4aAI\u9065\u611f\u89e3\u8bd1\u5927\u8d5b-\u53d8\u5316\u68c0\u6d4b\u8d5b\u9053**](https://rs.sensetime.com/competition/index.html#/info) *(\u5546\u6c64. 2020\u5e748\u6708)*   \n\u6570\u636e\u96c6\uff1a4662\u7ec4\uff0c\u5206\u8fa8\u7387\uff1a0.5~3m\uff0c\u89c4\u683c\uff1a512*512\uff0c\u53d8\u5316\u7c7b\u578b\u4e3a6\u79cd\u4e3b\u8981\u571f\u5730\u6027\u8d28\u4e4b\u95f4\u7684\u76f8\u4e92\u8f6c\u5316\uff1a\u6c34\u4f53\u3001\u5730\u9762\u3001\u4f4e\u77ee\u690d\u88ab\u3001\u6811\u6728\u3001\u5efa\u7b51\u7269\u3001\u8fd0\u52a8\u573a\u3002\u6bcf\u7ec4\u6570\u636e\u4e2d\uff0c\u524d\u540e\u65f6\u76f8\u7684\u4e24\u5f20\u56fe\u7247\u5404\u81ea\u5bf9\u5e94\u4e00\u5f20\u6807\u6ce8\u56fe\uff0c\u8868\u793a\u53d1\u751f\u53d8\u5316\u7684\u533a\u57df\u4ee5\u53ca\u8be5\u56fe\u7247\u53d8\u5316\u533a\u57df\u5185\u5404\u65f6\u671f\u7684\u571f\u5730\u6027\u8d28\u3002\u7b2c\u4e00\u540d\u7684\u89e3\u51b3\u65b9\u6848\u8be6\u89c1 [LiheYoung/SenseEarth2020-ChangeDetection](https://github.com/LiheYoung/SenseEarth2020-ChangeDetection)\u3002\n\n- [**2019 xView 2 Building Damage Asessment Challenge**](https://xview2.org) *(DIUx, Nov 2019)*     \n550k building footprints & 4 damage scale categories, 20 global locations and 7 disaster types (wildfire, landslides, dam collapses, volcanic eruptions, earthquakes/tsunamis, wind, flooding), Worldview-3 imagery (0.3m res.), pre-trained baseline model. Paper: [Gupta et al. 2019](https://arxiv.org/abs/1911.09296)\n\n- [**2019 \u9065\u611f\u56fe\u50cf\u7a00\u758f\u8868\u5f81\u4e0e\u667a\u80fd\u5206\u6790\u7ade\u8d5b-\u53d8\u5316\u68c0\u6d4b\u8d5b\u9053**](http://rscup.bjxintong.com.cn/#/theme/4) *(\u6b66\u6c49\u5927\u5b66. 2019\u5e747\u6708)*   \n\u672c\u9879\u7ade\u8d5b\u4ee5\u5149\u5b66\u9065\u611f\u56fe\u50cf\u4e3a\u5904\u7406\u5bf9\u8c61\uff0c\u53c2\u8d5b\u961f\u4f0d\u4f7f\u7528\u4e3b\u529e\u65b9\u63d0\u4f9b\u7684\u9065\u611f\u56fe\u50cf\u8fdb\u884c\u5efa\u7b51\u7269\u53d8\u5316\u68c0\u6d4b\uff0c\u4e3b\u529e\u65b9\u6839\u636e\u8bc4\u5206\u6807\u51c6\u5bf9\u53d8\u5316\u68c0\u6d4b\u7ed3\u679c\u8fdb\u884c\u7efc\u5408\u8bc4\u4ef7\u3002\u7ade\u8d5b\u4e2d\u5c06\u63d0\u4f9b\u4e24\u4e2a\u4e0d\u540c\u65f6\u95f4\u83b7\u53d6\u7684\u5927\u5c3a\u5ea6\u9ad8\u5206\u8fa8\u7387\u9065\u611f\u56fe\u50cf\uff08\u5305\u542b\u84dd\u3001\u7eff\u3001\u7ea2\u548c\u8fd1\u7ea2\u5916\u56db\u4e2a\u6ce2\u6bb5\uff09\uff0c\u4ee5\u53ca\u56fe\u50cf\u4e2d\u53d8\u5316\u533a\u57df\u7684\u4e8c\u503c\u5316\u6807\u6ce8\u6570\u636e\u96c6\u3002\n\n- [**2017 \u5e7f\u4e1c\u653f\u52a1\u6570\u636e\u521b\u65b0\u5927\u8d5b\u2014\u667a\u80fd\u7b97\u6cd5\u8d5b**](https://tianchi.aliyun.com/competition/entrance/231615/introduction) *(\u963f\u91cc\u5df4\u5df4. 2017\u5e7411\u6708)*    \n\u4f7f\u75282015\u5e74\u548c2017\u5e74\u5206\u522b\u83b7\u53d6\u5230\u7684\u5e7f\u4e1c\u7701\u67d0\u5730\u7684Quickbird\u536b\u661f\u5f71\u50cf\uff08\u5305\u542b\u84dd\u3001\u7eff\u3001\u7ea2\u548c\u8fd1\u7ea2\u5916\u56db\u4e2a\u6ce2\u6bb5\uff09\uff0c\u8bc6\u522b\u51fa\u4e24\u5e74\u4e4b\u95f4\u65b0\u589e\u7684\u4eba\u5de5\u5730\u4e0a\u5efa\u7b51\u7269\uff08\u4e0d\u5305\u62ec\u9053\u8def\uff09\u3002\u83b7\u80dc\u56e2\u961f\u7684\u89e3\u51b3\u65b9\u6848\u53ef\u4ee5\u5728[\u5929\u6c60](https://tianchi.aliyun.com/forum/postDetail?postId=3527)\u5b98\u7f51\u4e0a\u627e\u5230\u3002\n\n# Reference\n\n- [chrieke/awesome-satellite-imagery-datasets](https://github.com/chrieke/awesome-satellite-imagery-datasets)\n- [MinZHANG-WHU/Change-Detection-Review](https://github.com/MinZHANG-WHU/Change-Detection-Review)\n"
}